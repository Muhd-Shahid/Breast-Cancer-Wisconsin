{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Model to predict whether the cancer is benign or malignant on Breast Cancer Wisconsin Data Set !! Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization : GridSearch with Cross Validation for tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression : Hyperparameter Tuning and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_grid = dict(penalty=penalty,\n",
    "                  C=C,\n",
    "                  #class_weight=class_weight,\n",
    "                  solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "model.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "best_model = best_mdl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost : Hyperparameter Tuning and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "# A parameter grid for XGBoost\n",
    "param_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "model.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "best_model = best_mdl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier : Hyperparameter Tuning and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "# A parameter grid for GradientBoostingClassifier\n",
    "param_grid = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,250,500,750,1000,1250,1500,1750]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "model.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "best_model = best_mdl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest : Hyperparameter Tuning and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import GradientBoostingClassifier\n",
    "clf = RandomForestClassifier()\n",
    "# A parameter grid for GradientBoostingClassifier\n",
    "param_grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "model.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "best_model = best_mdl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test  = best_model.predict(X_test)\n",
    "y_probabilities_test = best_model.predict_proba(X_test)\n",
    "y_probabilities_success = y_probabilities_test[:, 1]\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_probabilities_success)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_probabilities_success)\n",
    "\n",
    "mse        = mean_squared_error(y_test, y_predicted_test)\n",
    "logloss    = log_loss(y_test, y_predicted_test)\n",
    "accuracy   = accuracy_score(y_test, y_predicted_test)\n",
    "precision  = precision_score(y_test, y_predicted_test, average='binary')\n",
    "recall     = recall_score(y_test, y_predicted_test, average='binary')\n",
    "F1         = f1_score(y_test, y_predicted_test)\n",
    "r2         = r2_score(y_test, y_predicted_test)\n",
    "auc        = roc_auc_score(y_test, y_predicted_test)\n",
    "cm         = confusion_matrix(y_test, y_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_mdl()\n",
    "Print_Model_Metrics()\n",
    "Plot_ROC_Precision_Recall()\n",
    "Plot_Confusion_Matrix()\n",
    "Plot_Predictor_Importance(True)\n",
    "#results_df = pd.DataFrame(data={'Observed':y_test, 'Predicted':y_predicted_test[:,1]})\n",
    "#results_df.to_csv('grid-search--outcome.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
